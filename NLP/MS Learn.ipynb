{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchtext\n",
    "import os\n",
    "import collections\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/\"\n",
    "batch_size = 32\n",
    "os.makedirs(data_dir, exist_ok=True)\n",
    "train_dataset = torchtext.datasets.AG_NEWS(\n",
    "    root=data_dir,\n",
    "    split=\"train\",\n",
    ")\n",
    "\n",
    "test_dataset = torchtext.datasets.AG_NEWS(\n",
    "    root=data_dir,\n",
    "    split=\"test\",\n",
    ")\n",
    "\n",
    "classes = [\"World\", \"Sports\", \"Business\", \"Sci/Tech\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = list(train_dataset)\n",
    "test_dataset = list(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First list of tokens:\n",
      "['wall', 'st', '.', 'bears', 'claw', 'back', 'into', 'the', 'black', '(', 'reuters', ')', 'reuters', '-', 'short-sellers', ',', 'wall', 'street', \"'\", 's', 'dwindling\\\\band', 'of', 'ultra-cynics', ',', 'are', 'seeing', 'green', 'again', '.']\n",
      "Second list of tokens:\n",
      "['carlyle', 'looks', 'toward', 'commercial', 'aerospace', '(', 'reuters', ')', 'reuters', '-', 'private', 'investment', 'firm', 'carlyle', 'group', ',', '\\\\which', 'has', 'a', 'reputation', 'for', 'making', 'well-timed', 'and', 'occasionally\\\\controversial', 'plays', 'in', 'the', 'defense', 'industry', ',', 'has', 'quietly', 'placed\\\\its', 'bets', 'on', 'another', 'part', 'of', 'the', 'market', '.']\n"
     ]
    }
   ],
   "source": [
    "tokenizer = torchtext.data.utils.get_tokenizer(\"basic_english\")\n",
    "\n",
    "first_sentence = train_dataset[0][1]\n",
    "second_sentence = train_dataset[1][1]\n",
    "\n",
    "f_tokens = tokenizer(first_sentence)\n",
    "s_tokens = tokenizer(second_sentence)\n",
    "\n",
    "print(f\"First list of tokens:\\n{f_tokens}\")\n",
    "print(f\"Second list of tokens:\\n{s_tokens}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Création du vocabulaire\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120000/120000 [00:03<00:00, 32512.34it/s]\n"
     ]
    }
   ],
   "source": [
    "counter = collections.Counter()\n",
    "\n",
    "for label, sentence in tqdm(train_dataset):\n",
    "    counter.update(tokenizer(sentence))\n",
    "\n",
    "vocabulary = torchtext.vocab.vocab(counter, min_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary contains 95810 tokens\n"
     ]
    }
   ],
   "source": [
    "vocab_size = len(vocabulary)\n",
    "print(f\"Vocabulary contains {vocab_size} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "itos = vocabulary.get_itos()\n",
    "stoi = vocabulary.get_stoi()\n",
    "\n",
    "\n",
    "def encode(x: str):\n",
    "    return [stoi[s] for s in tokenizer(x)]\n",
    "\n",
    "\n",
    "def decode(x: list[int]):\n",
    "    return [itos[s] for s in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 10, 12, 13, 14, 0, 15, 16, 17, 18, 19, 20, 14, 21, 22, 23, 24, 2]\n",
      "['wall', 'st', '.', 'bears', 'claw', 'back', 'into', 'the', 'black', '(', 'reuters', ')', 'reuters', '-', 'short-sellers', ',', 'wall', 'street', \"'\", 's', 'dwindling\\\\band', 'of', 'ultra-cynics', ',', 'are', 'seeing', 'green', 'again', '.']\n"
     ]
    }
   ],
   "source": [
    "vec = encode(first_sentence)\n",
    "print(vec)\n",
    "print(decode(vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1287/120000 [00:00<00:09, 11876.57it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120000/120000 [00:13<00:00, 8907.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bi-gram vocab size 481969\n"
     ]
    }
   ],
   "source": [
    "from torchtext.data.utils import ngrams_iterator\n",
    "\n",
    "bi_counter = collections.Counter()\n",
    "\n",
    "for label, sentence in tqdm(train_dataset):\n",
    "    bi_counter.update(\n",
    "        ngrams_iterator(\n",
    "            tokenizer(sentence),\n",
    "            ngrams=2,\n",
    "        )\n",
    "    )\n",
    "\n",
    "bi_vocab = torchtext.vocab.vocab(\n",
    "    bi_counter,\n",
    "    min_freq=2,\n",
    ")\n",
    "\n",
    "print(f\"Bi-gram vocab size {len(bi_vocab)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "bi_itos = bi_vocab.get_itos()\n",
    "bi_stoi = bi_vocab.get_stoi()\n",
    "\n",
    "\n",
    "def bi_encode(phrase: str):\n",
    "    return [bi_stoi[s] for s in tokenizer(phrase)]\n",
    "\n",
    "\n",
    "def bi_decode(tokens: list[int]):\n",
    "    return [bi_itos[s] for s in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 10, 12, 13, 14, 0, 15, 16, 17, 18, 19, 20, 14, 21, 22, 23, 24, 2]\n",
      "['wall', 'st', '.', 'bears', 'claw', 'back', 'into', 'the', 'black', '(', 'reuters', ')', 'reuters', '-', 'short-sellers', ',', 'wall', 'street', \"'\", 's', 'of', 'ultra-cynics', 'are', ',', 'seeing', 'green', 'again', 'wall st', '.']\n"
     ]
    }
   ],
   "source": [
    "bi_vec = encode(first_sentence)\n",
    "print(bi_vec)\n",
    "print(bi_decode(bi_vec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of Words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "\n",
    "def to_bow(text: str, bow_vocab_size=vocab_size):\n",
    "    result = torch.zeros(bow_vocab_size, dtype=torch.float32)\n",
    "\n",
    "    # retourne une série d'indices [0, 1, 0, ..., 52]\n",
    "    for idx in encode(text):\n",
    "        if idx < bow_vocab_size:\n",
    "            result[idx] += 1  # on compte le nombre d'occurence de chaque indice\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 10, 12, 13, 14, 0, 15, 16, 17, 18, 19, 20, 14, 21, 22, 23, 24, 2]\n",
      "tensor([2., 1., 2.,  ..., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "print(encode(first_sentence))\n",
    "print(to_bow(first_sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In PyTorch's DataLoader, the collate_fn is a function that is used to customize the way individual samples are collated (grouped together) into batches when loading data from a dataset. The purpose of the collate_fn is to handle the differences in sizes and shapes of individual samples so that they can be efficiently batched and processed by the neural network.\n",
    "\n",
    "Here's how it works:\n",
    "\n",
    "    Batching Process: When you use a DataLoader to load data from a dataset, the DataLoader groups a specified number of individual samples into a batch. Each batch is then passed to your model for processing. Since samples in a batch need to have consistent shapes (e.g., the same sequence length for text data), you might need to perform some preprocessing to ensure that all samples in a batch have the same shape.\n",
    "\n",
    "    Collate Function (collate_fn): The collate_fn parameter in the DataLoader allows you to specify a custom function that determines how individual samples should be combined into a batch. This function takes a list of individual samples and returns a batch tensor. The collate_fn is called by the DataLoader for each batch creation, and its role is to handle any necessary preprocessing to ensure consistent shapes within a batch.\n",
    "\n",
    "It can translated as:\n",
    "\n",
    "1. \"Fonction de Regroupement\" - This translates to \"Grouping Function,\" which roughly captures the idea that the function is responsible for grouping individual samples into batches.\n",
    "\n",
    "2. \"Fonction de Mise en Lot\" - This translates to \"Batching Function,\" which highlights the function's role in creating batches of data.\n",
    "\n",
    "3. \"Fonction de Prétraitement pour Lots\" - This translates to \"Preprocessing Function for Batches,\" which emphasizes the preprocessing aspect of the function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "def bowify(batch):\n",
    "    return (\n",
    "        torch.LongTensor([t[0] - 1 for t in batch]),  # labels\n",
    "        torch.stack([to_bow(t[1]) for t in batch]),  # BoW representation\n",
    "    )\n",
    "\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    collate_fn=bowify,\n",
    "    shuffle=True,\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    collate_fn=bowify,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "model = nn.Sequential(\n",
    "    nn.Linear(vocab_size, 4),\n",
    "    nn.LogSoftmax(dim=1),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    net: nn.Module,\n",
    "    loader: DataLoader,\n",
    "    lr: float = 1e-3,\n",
    "    optimizer: torch.optim.Optimizer | None = None,\n",
    "    loss_fn=nn.NLLLoss(),\n",
    "    epoch_size=None,\n",
    "    report_freq=200,\n",
    "):\n",
    "    r\"\"\"\n",
    "    Args:\n",
    "        epoch_size: permet d'arrêter le processus au cours de l'epoch actuel si on entrainer le modèle sur un certain nombre d'échantillon\n",
    "    \"\"\"\n",
    "    optimizer = (\n",
    "        optimizer if optimizer != None else torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    )\n",
    "    net.train()\n",
    "    total_loss, accuracy, count, idx = 0.0, 0.0, 0, 0\n",
    "\n",
    "    for labels, features in tqdm(loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = net(features)\n",
    "        loss: torch.Tensor = loss_fn(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        _, predicted = torch.max(output, 1)\n",
    "        accuracy += (labels == predicted).sum()\n",
    "        count += len(labels)\n",
    "        idx += 1\n",
    "\n",
    "        if idx % report_freq == 0:\n",
    "            print(f\"{count}: accuracy = {round(accuracy.item()/count * 100)}%\")\n",
    "\n",
    "        if epoch_size and count > epoch_size:\n",
    "            break\n",
    "\n",
    "    return total_loss, accuracy.item() / count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 125/7500 [00:09<09:17, 13.23it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(151.4331693649292, 0.7023809523809523)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_epoch(net=model, loader=train_loader, epoch_size=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 63/1000 [00:00<00:01, 622.25it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:01<00:00, 617.70it/s]\n"
     ]
    }
   ],
   "source": [
    "N = 1_000\n",
    "df = torch.zeros(vocab_size)\n",
    "\n",
    "for _, doc in tqdm(train_dataset[:N]):\n",
    "    for idx in set(encode(doc)):\n",
    "        df[idx] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_idf(s: str):\n",
    "    bow = to_bow(s)\n",
    "    # Laplace smoothing (lissage de Laplace) pour éviter la division par zéro\n",
    "    return bow * torch.log((N + 1) / (df + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wall\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       " \"Wall St. Bears Claw Back Into the Black (Reuters) Reuters - Short-sellers, Wall Street's dwindling\\\\band of ultra-cynics, are seeing green again.\")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, max_idx = tf_idf(first_sentence).max(dim=0)\n",
    "print(vocabulary.get_itos()[encode(first_sentence)[max_idx]]), first_sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "def padify(batch):\n",
    "    r\"\"\"\n",
    "    Args:\n",
    "        batch: est une liste de tuples de la forme (label, feature = text sequence)\n",
    "    \"\"\"\n",
    "\n",
    "    vec = [encode(sample[1]) for sample in batch]\n",
    "    max_length = max(map(len, vec))  # max length sequence in the mini-batch\n",
    "\n",
    "    return (\n",
    "        torch.LongTensor([elt[0] - 1 for elt in batch]),\n",
    "        torch.stack(\n",
    "            [\n",
    "                F.pad(\n",
    "                    torch.tensor(elt),\n",
    "                    # padding à droite (à la fin du vecteur)\n",
    "                    # (0, max_length - len(elt)) => ce tuple indique la taille du padding\n",
    "                    # On a pour un tenseur 1D, (padding_left, padding_right) le nombre de cases qu'on va ajouter après le padding\n",
    "                    # dans ce cas 0 à gauche et max_length - len(elt) à droite\n",
    "                    (0, max_length - len(elt)),\n",
    "                    mode=\"constant\",\n",
    "                    value=0,\n",
    "                )\n",
    "                for elt in vec\n",
    "            ]\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[    0,     1,     2,  ...,     0,     0,     0],\n",
      "        [   25,    26,    27,  ...,     0,     0,     0],\n",
      "        [   54,    41,    55,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [36336,   809,  2615,  ...,     0,     0,     0],\n",
      "        [  924,    16,    17,  ...,     0,     0,     0],\n",
      "        [ 7836,   892,  6107,  ...,     0,     0,     0]]) torch.Size([120000, 207])\n"
     ]
    }
   ],
   "source": [
    "train_labels, train_features = padify(train_dataset)\n",
    "print(train_features, train_features.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocabulary_size: int,\n",
    "        embed_dim: int,\n",
    "        num_class: int,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocabulary_size, embed_dim)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.embedding(x)\n",
    "        x = torch.mean(x, dim=1)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    collate_fn=padify,\n",
    "    shuffle=True,\n",
    ")\n",
    "net = EmbeddingClassifier(vocab_size, 32, len(classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 205/7500 [00:05<03:18, 36.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200: accuracy = 25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 404/7500 [00:10<03:24, 34.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400: accuracy = 26%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 605/7500 [00:15<02:36, 43.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600: accuracy = 25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 805/7500 [00:20<02:34, 43.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800: accuracy = 25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 1006/7500 [00:27<03:11, 33.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16000: accuracy = 25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 1203/7500 [00:35<05:24, 19.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19200: accuracy = 25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▊        | 1402/7500 [00:46<05:50, 17.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22400: accuracy = 25%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 1562/7500 [00:56<03:34, 27.74it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-62843.588962043636, 0.25059980806142035)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_epoch(net, train_loader, lr=1e-3, epoch_size=25000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingBagClassifier(nn.Module):\n",
    "    def __init__(self, vocabulary_size: int, embed_dim: int, num_class: int) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.embedding = nn.EmbeddingBag(vocabulary_size, embed_dim)\n",
    "        self.fc = nn.Linear(embed_dim, num_class)\n",
    "\n",
    "    def forward(self, text, offset):\n",
    "        x = self.embedding(text, offset)\n",
    "        return self.fc(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def offsetify(batch: tuple[int, str]):\n",
    "    x = [torch.tensor(encode(sample[1])) for sample in batch]  # encodage des séquences\n",
    "    # calcule de la taille de chaque vecteur\n",
    "    offset = [0] + [len(elt) for elt in x]\n",
    "    # somme cumulée croissante des tailles de vecteur\n",
    "    offset = torch.tensor(offset[:-1]).cumsum(dim=0)\n",
    "\n",
    "    return (\n",
    "        torch.LongTensor(\n",
    "            [sample[0] - 1 for sample in batch]\n",
    "        ),  # ajustement des labels du batch\n",
    "        torch.cat(x),  # concatenation pour avoir un vecteur de taille (1, N)\n",
    "        offset,  # vecteur des offsets\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([0, 1, 0]), tensor([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 10, 12, 13, 14,  0, 15,\n",
      "        16, 17, 18, 19, 20, 14, 21, 22, 23, 24,  2, 25, 26, 27, 28, 29,  9, 10,\n",
      "        11, 10, 12, 30, 31, 32, 25, 33, 14, 34, 35, 36, 37, 38, 39, 40, 41, 42,\n",
      "        43, 44,  7, 45, 46, 14, 35, 47, 48, 49, 50, 51, 52, 19,  7, 53,  2,  0,\n",
      "         1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 10, 12, 13, 14,  0, 15, 16,\n",
      "        17, 18, 19, 20, 14, 21, 22, 23, 24,  2]), tensor([ 0, 29, 71]))\n"
     ]
    }
   ],
   "source": [
    "res = offsetify(\n",
    "    [\n",
    "        (1, first_sentence),\n",
    "        (2, second_sentence),\n",
    "        (1, first_sentence),\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['carlyle',\n",
       " 'looks',\n",
       " 'toward',\n",
       " 'commercial',\n",
       " 'aerospace',\n",
       " '(',\n",
       " 'reuters',\n",
       " ')',\n",
       " 'reuters',\n",
       " '-',\n",
       " 'private',\n",
       " 'investment',\n",
       " 'firm',\n",
       " 'carlyle',\n",
       " 'group',\n",
       " ',',\n",
       " '\\\\which',\n",
       " 'has',\n",
       " 'a',\n",
       " 'reputation',\n",
       " 'for',\n",
       " 'making',\n",
       " 'well-timed',\n",
       " 'and',\n",
       " 'occasionally\\\\controversial',\n",
       " 'plays',\n",
       " 'in',\n",
       " 'the',\n",
       " 'defense',\n",
       " 'industry',\n",
       " ',',\n",
       " 'has',\n",
       " 'quietly',\n",
       " 'placed\\\\its',\n",
       " 'bets',\n",
       " 'on',\n",
       " 'another',\n",
       " 'part',\n",
       " 'of',\n",
       " 'the',\n",
       " 'market',\n",
       " '.']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decode(res[1][res[2][1] : res[2][2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.4289,  1.8165],\n",
      "        [-0.8550, -1.1369]]) tensor(-0.4011) tensor([ 0.1938, -0.9959])\n"
     ]
    }
   ],
   "source": [
    "res = torch.randn((2, 2))\n",
    "\n",
    "print(res, res.mean(), res.mean(dim=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN & LSTM\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RnnClassifier(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        vocabulary_size: int,\n",
    "        embed_dim: int,\n",
    "        hidden_dim: int,\n",
    "        num_classes: int,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.embedding = nn.Embedding(vocabulary_size, embed_dim)\n",
    "        self.rnn = nn.RNN(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.embedding(x)\n",
    "        x, h = self.rnn(x)\n",
    "\n",
    "        return self.fc(x.mean(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/7500 [00:00<22:20,  5.59it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 201/7500 [00:21<14:23,  8.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3200: accuracy = 24%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 312/7500 [00:33<12:49,  9.34it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(-1882.4174821265042, 0.2452076677316294)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=16,\n",
    "    collate_fn=padify,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "rnn_net = RnnClassifier(\n",
    "    vocab_size,\n",
    "    embed_dim=64,\n",
    "    hidden_dim=32,\n",
    "    num_classes=len(classes),\n",
    ")\n",
    "train_epoch(\n",
    "    rnn_net,\n",
    "    train_loader,\n",
    "    lr=1e-3,\n",
    "    epoch_size=5000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset,\n",
    "    batch_size=16,\n",
    "    collate_fn=padify,\n",
    "    shuffle=False,\n",
    ")\n",
    "\n",
    "rnn_net.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (labels, sentences) in enumerate(test_loader):\n",
    "        word_lookup = [itos[word] for word in sentences[batch_idx]]\n",
    "        unknown_vals = set(\"<unk>\")\n",
    "        word_lookup = [elt for elt in word_lookup if elt not in unknown_vals]\n",
    "\n",
    "        print(f\"Input text: {word_lookup}\")\n",
    "\n",
    "        predictions: torch.Tensor = rnn_net(sentences)\n",
    "        print(torch.argmax(predictions[batch_idx]))\n",
    "\n",
    "        print(\n",
    "            f\"Actual: value = {labels[batch_idx]}, class = {classes[labels[batch_idx]]}\"\n",
    "        )\n",
    "\n",
    "        print(\n",
    "            f\"Predicted: value = {predictions[0].argmax(0)}, class = {classes[predictions[0].argmax(0)]}\"\n",
    "        )\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OrderedDict([('weight_ih_l0',\n",
       "              tensor([[-0.0053,  0.3793, -0.5820, -0.5204, -0.2723],\n",
       "                      [ 0.1896, -0.0140,  0.5607, -0.0628,  0.1871]])),\n",
       "             ('weight_hh_l0',\n",
       "              tensor([[-0.2137, -0.1390],\n",
       "                      [-0.6755, -0.4683]])),\n",
       "             ('bias_ih_l0', tensor([-0.2915,  0.0262])),\n",
       "             ('bias_hh_l0', tensor([0.2795, 0.4243]))])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "torch.manual_seed(0)\n",
    "rnn_layer = nn.RNN(\n",
    "    input_size=5,\n",
    "    hidden_size=2,\n",
    "    num_layers=1,\n",
    "    batch_first=True,\n",
    ")\n",
    "\n",
    "rnn_layer.state_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "W_xh shape: torch.Size([2, 5]) \n",
      "\n",
      "B_xh shape: torch.Size([2]) \n",
      "\n",
      "W_hh shape: torch.Size([2, 2]) \n",
      "\n",
      "B_hh shape: torch.Size([2]) \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "w_xh = rnn_layer.weight_ih_l0\n",
    "b_xh = rnn_layer.bias_ih_l0\n",
    "\n",
    "w_hh = rnn_layer.weight_hh_l0\n",
    "b_hh = rnn_layer.bias_hh_l0\n",
    "\n",
    "print(\n",
    "    f\"\"\"\n",
    "W_xh shape: {w_xh.shape} \\n\n",
    "B_xh shape: {b_xh.shape} \\n\n",
    "W_hh shape: {w_hh.shape} \\n\n",
    "B_hh shape: {b_hh.shape} \\n\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 5]),\n",
       " tensor([[1., 1., 1., 1., 1.],\n",
       "         [2., 2., 2., 2., 2.],\n",
       "         [3., 3., 3., 3., 3.]]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input of shape (batch_size, seq_length, num_features=5)\n",
    "x_seq = torch.tensor([[1.0] * 5, [2.0] * 5, [3.0] * 5]).float()\n",
    "x_seq.size(), x_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time step 0 => Input:\t[[1. 1. 1. 1. 1.]]\n",
      "Hidden: [[-1.2921703  0.886815 ]]\n",
      "\n",
      "    Output (manual): [[-0.76684606  0.86455226]]\n",
      "\n",
      "    RNN output: [[-0.76684606  0.86455226]]\n",
      "\n",
      "    \n",
      "Time step 1 => Input:\t[[2. 2. 2. 2. 2.]]\n",
      "Hidden: [[-2.2928548  1.7474363]]\n",
      "\n",
      "    Output (manual): [[-0.961816   0.9794913]]\n",
      "\n",
      "    RNN output: [[-0.961816   0.9794913]]\n",
      "\n",
      "    \n",
      "Time step 2 => Input:\t[[3. 3. 3. 3. 3.]]\n",
      "Hidden: [[-3.2935395  2.6080575]]\n",
      "\n",
      "    Output (manual): [[-0.9944769  0.9968337]]\n",
      "\n",
      "    RNN output: [[-0.9944769  0.9968337]]\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "# c'est comme créer un Dataset ayant un seul batch de 3 séquences)\n",
    "output, hn = rnn_layer(x_seq.reshape(1, 3, 5))\n",
    "manual_output = []\n",
    "\n",
    "for t in range(3):\n",
    "    xt = x_seq[t].reshape(1, 5)\n",
    "    print(f\"Time step {t} => Input:\\t{xt.numpy()}\")\n",
    "\n",
    "    ht = torch.matmul(xt, torch.transpose(w_xh, 0, 1)) + b_xh\n",
    "    print(f\"Hidden: {ht.detach().numpy()}\")\n",
    "\n",
    "    if t > 0:\n",
    "        prev_h = manual_output[t - 1]\n",
    "    else:\n",
    "        prev_h = torch.zeros_like(ht)\n",
    "\n",
    "    ot = ht + torch.matmul(prev_h, torch.transpose(w_hh, 0, 1)) + b_hh\n",
    "    ot = torch.tanh(ot)\n",
    "    manual_output.append(ot)\n",
    "\n",
    "    print(\n",
    "        f\"\"\"\n",
    "    Output (manual): {ot.detach().numpy()}\\n\n",
    "    RNN output: {output[:, t].detach().numpy()}\\n\n",
    "    \"\"\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def char_tokenizer(word: str):\n",
    "    return list(word)  # equals to [letter for letter in word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 120000/120000 [00:01<00:00, 71780.00it/s]\n"
     ]
    }
   ],
   "source": [
    "counter = collections.Counter()\n",
    "\n",
    "for _, sentence in tqdm(train_dataset):\n",
    "    counter.update(char_tokenizer(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size: 82\n",
      "Encoding of 'a' is 1\n",
      "Character with code 13 is c\n"
     ]
    }
   ],
   "source": [
    "vocabulary = torchtext.vocab.vocab(counter)\n",
    "vocabulary_size = len(vocabulary)\n",
    "\n",
    "print(\n",
    "    f\"Vocab size: {vocabulary_size}\\nEncoding of 'a' is {vocabulary['a']}\\nCharacter with code 13 is {vocabulary.get_itos()[13]}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.zeros()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "atom",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
